{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "#my version\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#layers for NN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "#oretrained model for transfer learning\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg19\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 getting neural netowkr working\n",
    "Training neural network similar to sklearn models but a bit more complicated. Lets use the titanic dataset we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of our training data: (712, 9) \n",
      "Length of our Testing data: (179,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>pclass_2</th>\n",
       "      <th>pclass_3</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived                                               name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    age  sibsp  parch            ticket     fare cabin  sex_male  pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN         1         0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85         0         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN         0         0   \n",
       "3  35.0      1      0            113803  53.1000  C123         0         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN         1         0   \n",
       "\n",
       "   pclass_3  embarked_Q  embarked_S  \n",
       "0         1           0           1  \n",
       "1         0           0           0  \n",
       "2         1           0           1  \n",
       "3         0           0           1  \n",
       "4         1           0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raw url to get csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/CUNYTechPrep/2020-fall-data-science/master/Week5-RandomForest/data/titanic.csv')\n",
    "\n",
    "df = pd.get_dummies(df, columns=['sex', 'pclass', 'embarked'], drop_first=True)\n",
    "selected_features = ['fare', 'age', 'sex_male', 'pclass_2', 'pclass_3', 'sibsp', 'parch', 'embarked_Q', 'embarked_S']\n",
    "df['age'] = df['age'].fillna(999)\n",
    "\n",
    "X = df[selected_features]\n",
    "\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "print('Length of our training data:', X_train.shape, '\\nLength of our Testing data:', y_test.shape)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are made of layers with the layers themselves made up of neurons<br>\n",
    "Input layer - Multiple hidden layers - Output layer<br>\n",
    "\n",
    "We will build our own networks layer with sequential fcn.<br>\n",
    "Layers contain the actual neurosn are called Dense layers in tensorflow. TO get a deep network, we need more dense layers. For a wide network, add more neurons in each layer.<br>\n",
    "Tensorflow expects 2 params for dense layers. 1st is num of neurons. Good fit is between 64-1024 starting point.<br>\n",
    "Other param is activationf csn. These are important, for now set to relu.<br>\n",
    "Last dense layer is the output layer. Num of neurons should be equal to num of classes we want to predict (in our case, we have two class to predict which is whether or not passenger survived).<br>\n",
    "If problem has two clases (like our example) put 1 and set activation to sigmoid. If problem is multiclass with N classes, set the num to be N and activation to softmax.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decisiontree = DecisionTree()\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next up, compile the model PRIOR to training it. Three params, optimizer, loss fcn, metrics.<br>\n",
    "multiple Optimizers , each has different params that can be changed. tf.keras.optimizer.Adam() is good choice for most problems.<br>\n",
    "Loss fcn depends on problem. Binary class, use binary_crossentropy. Multiclass problem, use sparse_categorical_crossentropy. Regression, use mse.<br>\n",
    "Metric is what metric we want the model to report while training. We can use accuracy. For regression problem, use mse or mae.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['acc'])\n",
    "#compile fcn operates inpalce, we dont retrun the model. Remember fit from sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can train. Depends what we want to do. Pass training and test set like usualm but define number of epochs. How long we want the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 1s 15ms/step - loss: 5.7056 - acc: 0.6250 - val_loss: 0.9497 - val_acc: 0.5556\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.0186 - acc: 0.5469 - val_loss: 1.5223 - val_acc: 0.5694\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.0112 - acc: 0.6578 - val_loss: 1.0070 - val_acc: 0.5972\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8379 - acc: 0.6844 - val_loss: 1.1521 - val_acc: 0.6111\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8431 - acc: 0.6734 - val_loss: 0.8765 - val_acc: 0.6806\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8899 - acc: 0.6672 - val_loss: 1.1519 - val_acc: 0.6944\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7200 - acc: 0.6891 - val_loss: 1.1656 - val_acc: 0.6806\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8624 - acc: 0.6766 - val_loss: 0.7335 - val_acc: 0.6111\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7366 - acc: 0.6891 - val_loss: 0.8640 - val_acc: 0.5972\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8227 - acc: 0.6844 - val_loss: 0.8770 - val_acc: 0.6806\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7459 - acc: 0.7016 - val_loss: 0.6591 - val_acc: 0.6389\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7298 - acc: 0.7047 - val_loss: 0.8214 - val_acc: 0.6528\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5688 - acc: 0.7250 - val_loss: 0.7317 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8344 - acc: 0.7000 - val_loss: 0.9423 - val_acc: 0.6806\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6769 - acc: 0.7203 - val_loss: 0.8335 - val_acc: 0.5556\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6992 - acc: 0.7000 - val_loss: 0.6213 - val_acc: 0.6389\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5677 - acc: 0.7281 - val_loss: 0.8448 - val_acc: 0.6667\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9829 - acc: 0.6906 - val_loss: 0.6349 - val_acc: 0.7222\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8603 - acc: 0.7422 - val_loss: 0.6002 - val_acc: 0.6806\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7229 - acc: 0.7422 - val_loss: 0.8385 - val_acc: 0.7361\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8181 - acc: 0.7328 - val_loss: 0.5760 - val_acc: 0.7361\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6087 - acc: 0.7484 - val_loss: 0.6746 - val_acc: 0.7222\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5126 - acc: 0.7766 - val_loss: 0.5791 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3080 - acc: 0.7344 - val_loss: 2.6324 - val_acc: 0.7083\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8846 - acc: 0.7391 - val_loss: 0.6681 - val_acc: 0.7361\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6702 - acc: 0.7328 - val_loss: 0.6522 - val_acc: 0.7639\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6958 - acc: 0.7484 - val_loss: 1.3995 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9001 - acc: 0.7516 - val_loss: 1.5175 - val_acc: 0.7222\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.1247 - acc: 0.7563 - val_loss: 1.2658 - val_acc: 0.6250\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.2312 - acc: 0.7172 - val_loss: 1.1018 - val_acc: 0.7361\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.2934 - acc: 0.7500 - val_loss: 0.5633 - val_acc: 0.7222\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.3587 - acc: 0.7344 - val_loss: 1.4338 - val_acc: 0.6944\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8001 - acc: 0.7563 - val_loss: 0.6790 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5355 - acc: 0.7812 - val_loss: 0.6839 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5924 - acc: 0.7609 - val_loss: 0.6263 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4766 - acc: 0.7750 - val_loss: 0.5257 - val_acc: 0.7639\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5217 - acc: 0.7688 - val_loss: 0.8061 - val_acc: 0.6944\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6616 - acc: 0.7359 - val_loss: 1.3904 - val_acc: 0.6806\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7165 - acc: 0.7594 - val_loss: 0.8439 - val_acc: 0.7639\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5214 - acc: 0.7953 - val_loss: 0.5525 - val_acc: 0.7639\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4742 - acc: 0.7672 - val_loss: 0.6562 - val_acc: 0.7083\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6636 - acc: 0.7453 - val_loss: 0.5521 - val_acc: 0.7083\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5047 - acc: 0.7797 - val_loss: 0.5503 - val_acc: 0.7083\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5694 - acc: 0.7641 - val_loss: 1.0720 - val_acc: 0.7083\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7841 - acc: 0.7516 - val_loss: 0.6417 - val_acc: 0.7083\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4742 - acc: 0.7969 - val_loss: 0.5592 - val_acc: 0.7361\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 1.0899 - acc: 0.7437 - val_loss: 1.5930 - val_acc: 0.6806\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5344 - acc: 0.7734 - val_loss: 0.6235 - val_acc: 0.7083\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4787 - acc: 0.7828 - val_loss: 0.5291 - val_acc: 0.7778\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4684 - acc: 0.7859 - val_loss: 0.5120 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4438 - acc: 0.8078 - val_loss: 0.8700 - val_acc: 0.7083\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6006 - acc: 0.7797 - val_loss: 0.7325 - val_acc: 0.6528\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6203 - acc: 0.7516 - val_loss: 0.6677 - val_acc: 0.7222\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5028 - acc: 0.7844 - val_loss: 0.9141 - val_acc: 0.7083\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5971 - acc: 0.7844 - val_loss: 0.6188 - val_acc: 0.6806\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6307 - acc: 0.7734 - val_loss: 1.2194 - val_acc: 0.7361\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7247 - acc: 0.7656 - val_loss: 0.6982 - val_acc: 0.7222\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5758 - acc: 0.7891 - val_loss: 0.6166 - val_acc: 0.7222\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4911 - acc: 0.7828 - val_loss: 1.5198 - val_acc: 0.7222\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8969 - acc: 0.7563 - val_loss: 0.5255 - val_acc: 0.7361\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4814 - acc: 0.7969 - val_loss: 0.4920 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4671 - acc: 0.8000 - val_loss: 0.6665 - val_acc: 0.7222\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5531 - acc: 0.7828 - val_loss: 0.7055 - val_acc: 0.7083\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4644 - acc: 0.7984 - val_loss: 0.5906 - val_acc: 0.6944\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5510 - acc: 0.7922 - val_loss: 1.1979 - val_acc: 0.6528\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8478 - acc: 0.7672 - val_loss: 2.7513 - val_acc: 0.7361\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.9136 - acc: 0.7922 - val_loss: 0.6071 - val_acc: 0.7222\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7806 - acc: 0.7531 - val_loss: 0.5874 - val_acc: 0.7083\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5399 - acc: 0.7812 - val_loss: 0.9204 - val_acc: 0.6528\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7713 - acc: 0.7750 - val_loss: 1.1197 - val_acc: 0.7778\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5716 - acc: 0.7797 - val_loss: 0.7878 - val_acc: 0.7222\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5695 - acc: 0.7844 - val_loss: 0.7265 - val_acc: 0.7222\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 0.7984 - val_loss: 0.5294 - val_acc: 0.8056\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4376 - acc: 0.8078 - val_loss: 0.5603 - val_acc: 0.7361\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5263 - acc: 0.7922 - val_loss: 0.5366 - val_acc: 0.7639\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4406 - acc: 0.8094 - val_loss: 0.6803 - val_acc: 0.7222\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4358 - acc: 0.8062 - val_loss: 0.5078 - val_acc: 0.7361\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4814 - acc: 0.7875 - val_loss: 0.8091 - val_acc: 0.7222\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7770 - acc: 0.7906 - val_loss: 0.6684 - val_acc: 0.6389\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4959 - acc: 0.7953 - val_loss: 0.5292 - val_acc: 0.7361\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4228 - acc: 0.7984 - val_loss: 0.4993 - val_acc: 0.7639\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4208 - acc: 0.8141 - val_loss: 0.5325 - val_acc: 0.7361\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4431 - acc: 0.8047 - val_loss: 0.5021 - val_acc: 0.7639\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4489 - acc: 0.8047 - val_loss: 0.5538 - val_acc: 0.7361\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4652 - acc: 0.7953 - val_loss: 0.6171 - val_acc: 0.7778\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5144 - acc: 0.7875 - val_loss: 0.5098 - val_acc: 0.7639\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4896 - acc: 0.7953 - val_loss: 0.6498 - val_acc: 0.6528\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4084 - acc: 0.8078 - val_loss: 0.5096 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4169 - acc: 0.8031 - val_loss: 0.5996 - val_acc: 0.7361\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4139 - acc: 0.8203 - val_loss: 0.5440 - val_acc: 0.7361\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4284 - acc: 0.8031 - val_loss: 0.5482 - val_acc: 0.7222\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5975 - acc: 0.7859 - val_loss: 0.6449 - val_acc: 0.7222\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4293 - acc: 0.8188 - val_loss: 0.5685 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4169 - acc: 0.8203 - val_loss: 0.5757 - val_acc: 0.7361\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5954 - acc: 0.7906 - val_loss: 1.1503 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6539 - acc: 0.7844 - val_loss: 0.6959 - val_acc: 0.6528\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4776 - acc: 0.7922 - val_loss: 0.5386 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4213 - acc: 0.8109 - val_loss: 0.7237 - val_acc: 0.7361\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4713 - acc: 0.8016 - val_loss: 0.5864 - val_acc: 0.7361\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4326 - acc: 0.8203 - val_loss: 0.6790 - val_acc: 0.7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x238989719a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 100\n",
    "model.fit(X_train, y_train, epochs=epoch, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.5131 - acc: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5131254196166992, 0.8212290406227112]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can tinker with model but not much improvement since neural networks are very data hungry. Less than 1000 examples, our dataset is not big enough. No strict num on a good amount of data but at least 10k+ examples is good. <br>\n",
    "100k is much better and best models use traning sets in the millions. Neural networks most useful for image recognition or NLP, not usually with traditional data set like titanic.\n",
    "\n",
    "# Part 2 image recognition with convolutional neural networks\n",
    "We will use keras load_data() fcn to read in data and it can convienently split into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2389e185ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view images to ensure it looks good and set size of plot\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#one image\n",
    "img = x_train[590]\n",
    "\n",
    "#reshaoe to the 28x28 matrix\n",
    "img = img.reshape(28,28)\n",
    "\n",
    "#plot reshaped image\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train #checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "y_train = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers apply filters to image to transform input. Exact filters are learned throughout training.<br>\n",
    "Build model same way, add layers. to make a CNN, add the convolutional layers at beginning and some MaxPooling layers which combine output of previous convolutional layers.<br>\n",
    "First layer needs an input_shape with input of our image, kernel_size is almost always (3,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "#start with some conv2D layers alternating with some maxPool layers\n",
    "#filter size inc. add chunks of conv2D and MaxPool up to 4 groups\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(28,28, 1),filters=28,kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=28, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=28, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=28, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "#need to flatten layer before going into dense layers\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1688/1688 [==============================] - 42s 24ms/step - loss: 0.1504 - acc: 0.9531 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "Epoch 2/6\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0543 - acc: 0.9837 - val_loss: 0.0350 - val_acc: 0.9898\n",
      "Epoch 3/6\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0389 - acc: 0.9892 - val_loss: 0.0352 - val_acc: 0.9908\n",
      "Epoch 4/6\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0310 - acc: 0.9909 - val_loss: 0.0441 - val_acc: 0.9888\n",
      "Epoch 5/6\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0279 - acc: 0.9919 - val_loss: 0.0364 - val_acc: 0.9903\n",
      "Epoch 6/6\n",
      "1688/1688 [==============================] - 40s 24ms/step - loss: 0.0220 - acc: 0.9935 - val_loss: 0.0335 - val_acc: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2389d9e86a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 6\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0270 - acc: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02695588394999504, 0.9927999973297119]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 3 transfer learning\n",
    "If asked to train an image classifier tomorrow, we would use transfer learning. Idea is to make use of models that other orgs have trained for a long time on a bunch of data. Can download their weights and add layers on end for our purpose.<br>\n",
    "Can follow this: https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a <br>\n",
    "First, use new data set, we can use cifar10 data set, classic benchmark: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 32, 32, 3)\n",
    "y_train = y_train.reshape(-1)\n",
    "x_test = x_test.reshape(-1, 32, 32, 3)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2389e054580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view images\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#select one image\n",
    "img = x_train[326]\n",
    "\n",
    "#reshape img to 28x28 matrix\n",
    "img = img.reshape(32,32,3)\n",
    "\n",
    "#plot reshaped image\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.6027 - acc: 0.4002 - val_loss: 1.1896 - val_acc: 0.5716\n",
      "Epoch 2/15\n",
      "1407/1407 [==============================] - 91s 64ms/step - loss: 1.1375 - acc: 0.5974 - val_loss: 0.9469 - val_acc: 0.6642\n",
      "Epoch 3/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.9312 - acc: 0.6758 - val_loss: 0.8643 - val_acc: 0.6976\n",
      "Epoch 4/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.8053 - acc: 0.7224 - val_loss: 0.7796 - val_acc: 0.7336\n",
      "Epoch 5/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.7214 - acc: 0.7491 - val_loss: 0.7604 - val_acc: 0.7366\n",
      "Epoch 6/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.6425 - acc: 0.7779 - val_loss: 0.7239 - val_acc: 0.7548\n",
      "Epoch 7/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.5804 - acc: 0.8000 - val_loss: 0.7429 - val_acc: 0.7540\n",
      "Epoch 8/15\n",
      "1407/1407 [==============================] - 91s 64ms/step - loss: 0.5234 - acc: 0.8178 - val_loss: 0.7772 - val_acc: 0.7556\n",
      "Epoch 9/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.4731 - acc: 0.8368 - val_loss: 0.7335 - val_acc: 0.7582\n",
      "Epoch 10/15\n",
      "1407/1407 [==============================] - 91s 64ms/step - loss: 0.4404 - acc: 0.8487 - val_loss: 0.8019 - val_acc: 0.7478\n",
      "Epoch 11/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.3934 - acc: 0.8644 - val_loss: 0.8026 - val_acc: 0.7644\n",
      "Epoch 12/15\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.3622 - acc: 0.8751 - val_loss: 0.8224 - val_acc: 0.7590\n",
      "Epoch 13/15\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 0.3442 - acc: 0.8834 - val_loss: 0.7997 - val_acc: 0.7668\n",
      "Epoch 14/15\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 0.3176 - acc: 0.8914 - val_loss: 0.8228 - val_acc: 0.7660\n",
      "Epoch 15/15\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 0.2928 - acc: 0.8991 - val_loss: 0.8953 - val_acc: 0.7534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2389e343580>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making some tweaks to input shape but overal using same model to benchmark\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(32,32, 3),filters=32,kernel_size=(3,3), strides=(1,1), activation=\"relu\")) #change here!!\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation=\"relu\")) #here too\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation=\"relu\")) #filter values here as well\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "#need to flatten layer before going into dense layers\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3)) #add this\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3)) #and here\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "#can we do other metrics besides accuracy?\n",
    "epochs = 15\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.9482 - acc: 0.7429\n",
      "scratch CNN accuracy 0.742900013923645\n"
     ]
    }
   ],
   "source": [
    "#evaluating our from-scratch CNN model\n",
    "print('scratch CNN accuracy', model.evaluate(x_test, y_test)[1])\n",
    "#75% accuracy pretty good for classificatio problem with 10 classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now for transfer model lets create validation set to use\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.input_layer.InputLayer object at 0x00000238B5B14100&gt;</td>\n",
       "      <td>input_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B14460&gt;</td>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E319370&gt;</td>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5B1AA30&gt;</td>\n",
       "      <td>block1_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E34BEB0&gt;</td>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B1A250&gt;</td>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5B24310&gt;</td>\n",
       "      <td>block2_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B1A2E0&gt;</td>\n",
       "      <td>block3_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B246D0&gt;</td>\n",
       "      <td>block3_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E2181C0&gt;</td>\n",
       "      <td>block3_conv3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C5D370&gt;</td>\n",
       "      <td>block3_conv4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C64CD0&gt;</td>\n",
       "      <td>block3_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64100&gt;</td>\n",
       "      <td>block4_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64550&gt;</td>\n",
       "      <td>block4_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B2E6A0&gt;</td>\n",
       "      <td>block4_conv3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C74670&gt;</td>\n",
       "      <td>block4_conv4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C74D00&gt;</td>\n",
       "      <td>block4_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64A30&gt;</td>\n",
       "      <td>block5_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B2EAF0&gt;</td>\n",
       "      <td>block5_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64D00&gt;</td>\n",
       "      <td>block5_conv3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C84C10&gt;</td>\n",
       "      <td>block5_conv4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C8B730&gt;</td>\n",
       "      <td>block5_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;keras.layers.reshaping.flatten.Flatten object at 0x00000238B5C8B250&gt;</td>\n",
       "      <td>flatten_4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Layer Type  \\\n",
       "0               <keras.engine.input_layer.InputLayer object at 0x00000238B5B14100>   \n",
       "1          <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B14460>   \n",
       "2          <keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E319370>   \n",
       "3   <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5B1AA30>   \n",
       "4          <keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E34BEB0>   \n",
       "5          <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B1A250>   \n",
       "6   <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5B24310>   \n",
       "7          <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B1A2E0>   \n",
       "8          <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B246D0>   \n",
       "9          <keras.layers.convolutional.conv2d.Conv2D object at 0x000002389E2181C0>   \n",
       "10         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C5D370>   \n",
       "11  <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C64CD0>   \n",
       "12         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64100>   \n",
       "13         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64550>   \n",
       "14         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B2E6A0>   \n",
       "15         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C74670>   \n",
       "16  <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C74D00>   \n",
       "17         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64A30>   \n",
       "18         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5B2EAF0>   \n",
       "19         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C64D00>   \n",
       "20         <keras.layers.convolutional.conv2d.Conv2D object at 0x00000238B5C84C10>   \n",
       "21  <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000238B5C8B730>   \n",
       "22           <keras.layers.reshaping.flatten.Flatten object at 0x00000238B5C8B250>   \n",
       "\n",
       "      Layer Name  Layer Trainable  \n",
       "0        input_1            False  \n",
       "1   block1_conv1            False  \n",
       "2   block1_conv2            False  \n",
       "3    block1_pool            False  \n",
       "4   block2_conv1            False  \n",
       "5   block2_conv2            False  \n",
       "6    block2_pool            False  \n",
       "7   block3_conv1            False  \n",
       "8   block3_conv2            False  \n",
       "9   block3_conv3            False  \n",
       "10  block3_conv4            False  \n",
       "11   block3_pool            False  \n",
       "12  block4_conv1            False  \n",
       "13  block4_conv2            False  \n",
       "14  block4_conv3            False  \n",
       "15  block4_conv4            False  \n",
       "16   block4_pool            False  \n",
       "17  block5_conv1            False  \n",
       "18  block5_conv2            False  \n",
       "19  block5_conv3            False  \n",
       "20  block5_conv4            False  \n",
       "21   block5_pool            False  \n",
       "22     flatten_4            False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "\n",
    "#load the model\n",
    "vgg = vgg19.VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = keras.layers.Flatten()(output)\n",
    "\n",
    "vgg_model = Model(vgg.input, output)\n",
    "\n",
    "#freeze bottom layers and print them out\n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "pd.set_option('max_colwidth', None)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 115s 82ms/step\n",
      "157/157 [==============================] - 13s 82ms/step\n",
      "313/313 [==============================] - 27s 85ms/step\n"
     ]
    }
   ],
   "source": [
    "#we can use the vgg model as a feature extractor, we can use it to make predictions and then store them and feed into our own models\n",
    "train_features_vgg = vgg_model.predict(x_train)\n",
    "validation_features_vgg = vgg_model.predict(x_val)\n",
    "test_features_vgg = vgg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = vgg_model.output_shape[1]\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(input_shape,)))\n",
    "model.add(Dense(256, activation='relu', input_dim=input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.5528 - accuracy: 0.4472 - val_loss: 1.3199 - val_accuracy: 0.5300\n",
      "Epoch 2/20\n",
      "1265/1407 [=========================>....] - ETA: 0s - loss: 1.3628 - accuracy: 0.5188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36676\\2271644426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_features_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "model.fit(train_features_vgg, y_train, validation_data=(validation_features_vgg, y_val), epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
